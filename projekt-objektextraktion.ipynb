{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 8928375,
     "sourceType": "datasetVersion",
     "datasetId": 5186039
    },
    {
     "sourceId": 182855516,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Adaption der Objektextraktion\nHallo! Wir wollen beliebige, selbstgewählte Objektkategorien auf Fotos (mit einfachem Hintergrund) erkennen. Sie brauchen also Fotos. Laden Sie diese auf Google-Drive hoch, oder nutzen Sie vorerst mal die [Giraffen-Puzzleteile](https://drive.google.com/drive/folders/1hXzFL_2Ot5PM3hvQCsgFhFeHV4wtG8E-?usp=drive_link). Die Daten sind auch im [dsci-Sharepoint-Ordner](https://ostch.sharepoint.com/:f:/r/teams/TS-FHS-IPM/Shared%20Documents/lehre%20und%20weiterbildung/21_Winf_MSc/10%20Module/DSCI/HS2024/Praktikum/Daten_Giraffe?csf=1&web=1&e=0OQ5db) abgelegt.\n\nZiel dieses Notebooks ist es, den Hintergrund der Bilder so gut zu \"verstehen\", dass das Skript `objekt_extraction.py` anschliessend aus allen Fotos die Objekte extrahieren kann. Auf einem Foto können mehrere Objekte abgebildet sein, wir extrahieren dann aber pro Objekt ein Bild. \"verstehen\" bedeutet gewisse Parameterwerte zu bestimmen, mit denen die Objektextraktion zuverlässig funktioniert.\n\nAm Ende dieses Notebooks kennen wir diese Parameterwerte, und es wird das Skript `object_extraction.py` mit diesen Parameterwerten ausgeführt. Es extrahiert von allen Ihren Bildern die Ausschnitte (mit Objekten drin), welche wir für die Klassifizierung später brauchen.\n\nDie Objektextraktion im Skript object_extraction.py kann je nach Beleuchtungsverhältnissen etc. unterschiedlich gut klappen und muss allenfalls adaptiert werden. Mit diesem Notebook können die einzelnen Verarbeitungsschritte dieses Skripts detailliert nachvollzogen werden. Die Parameter, deren Werte wir bestimmen müssen, heissen:",
   "metadata": {
    "id": "a2f63220-c2ea-4951-bd89-a29112e28c50"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pr = 225,400 #PREPROCESSING_RESOLUTION, --preprocessing_resolution\n",
    "tf = 0  #TOP_FRACTION, --top_fraction\n",
    "bf = 0  #BOTTOM_FRACTION, --bottom_fraction\n",
    "lf = 0  #LEFT_FRACTION, --left_fraction\n",
    "rf = 0.3  #RIGHT_FRACTION, --right_fraction\n",
    "\n",
    "\n",
    "\n",
    "sign = +1 # +1 for black background, -1 for white background\n",
    "vth = 160    #VALUE_THRESHOLD, --value_threshold\n",
    "es = 2     #EROSION_SIZE, --erosion_size\n",
    "ds = 3     #DILATION_SIZE, --dilation_size\n",
    "mpx = 200 #MINIMUM NUMBER OF PIXELS, --minimum_number_of_pixels\n",
    "Bilddateiendung = 'jpg' #Dateiendung der Bilder, ohne \".\""
   ],
   "metadata": {
    "id": "f7XpTgSVr9eu",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:32.280647Z",
     "iopub.execute_input": "2024-09-23T12:05:32.281066Z",
     "iopub.status.idle": "2024-09-23T12:05:32.287775Z",
     "shell.execute_reply.started": "2024-09-23T12:05:32.281033Z",
     "shell.execute_reply": "2024-09-23T12:05:32.286363Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Die angegebenen Werte sind Standardwerte, die Sie anpassen sollen.",
   "metadata": {
    "id": "XfaPYwopsEui"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Setup und Zugriff zu den Bilddaten",
   "metadata": {
    "id": "wqiwlde0bA5d"
   }
  },
  {
   "cell_type": "code",
   "source": "!ls /kaggle/usr/lib/object_extraction",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:34.530969Z",
     "iopub.execute_input": "2024-09-23T12:05:34.531353Z",
     "iopub.status.idle": "2024-09-23T12:05:35.722122Z",
     "shell.execute_reply.started": "2024-09-23T12:05:34.531326Z",
     "shell.execute_reply": "2024-09-23T12:05:35.720757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "!tail /kaggle/usr/lib/object_extraction/object_extraction.py",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-23T12:06:22.368304Z",
     "iopub.execute_input": "2024-09-23T12:06:22.368746Z",
     "iopub.status.idle": "2024-09-23T12:06:23.546112Z",
     "shell.execute_reply.started": "2024-09-23T12:06:22.368710Z",
     "shell.execute_reply": "2024-09-23T12:06:23.544198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from object_extraction import *",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-23T12:06:26.549386Z",
     "iopub.execute_input": "2024-09-23T12:06:26.549851Z",
     "iopub.status.idle": "2024-09-23T12:06:26.556112Z",
     "shell.execute_reply.started": "2024-09-23T12:06:26.549811Z",
     "shell.execute_reply": "2024-09-23T12:06:26.554863Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "#if os.path.exists('/content/drive'):\n",
    "#    from google.colab import drive\n",
    "#    drive.mount('/content/drive')\n",
    "#else:\n",
    "\n",
    "!ls Daten|head"
   ],
   "metadata": {
    "id": "4hm0hn6gNT-I",
    "outputId": "2e934f5a-5aea-4403-f184-3532ea000aff",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:06:31.128194Z",
     "iopub.execute_input": "2024-09-23T12:06:31.128581Z",
     "iopub.status.idle": "2024-09-23T12:06:32.302326Z",
     "shell.execute_reply.started": "2024-09-23T12:06:31.128552Z",
     "shell.execute_reply": "2024-09-23T12:06:32.300897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Wenn das geklappt hat, haben Sie Zugriff auf die Daten! In der nächsten Zelle muss einfach der Pfad richtig angepasst werden. Dann sind Sie gerüstet für den Rest des Notebooks. Kopieren Sie jenen Pfad als String in die folgende Variable:",
   "metadata": {
    "id": "DmkXsjkqQP-_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path #Path ist eien Klasse, welche den Umgang mit Dateipfaden erleichtert\n",
    "pfad_zu_daten_string = 'Daten'\n",
    "pfad_zu_daten = Path(pfad_zu_daten_string)\n",
    "\n",
    "pfad_zu_object_extraction =  Path('object_extraction')"
   ],
   "metadata": {
    "id": "AfviVYZkRHky",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:06:46.956742Z",
     "iopub.execute_input": "2024-09-23T12:06:46.957188Z",
     "iopub.status.idle": "2024-09-23T12:06:46.963949Z",
     "shell.execute_reply.started": "2024-09-23T12:06:46.957158Z",
     "shell.execute_reply": "2024-09-23T12:06:46.962406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Als nächstes benötigen wir den Pfad zu `lcl_colab/1_object_extraction`. Er muss in sys.path zu finden sein. In der nächsten Zelle wird dies getestet:",
   "metadata": {
    "id": "Ra7HxtBPTL_K"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Nun sollte die Datei `object_extraction.py` gefunden werden und das Modul object_extraction importiert werden können",
   "metadata": {
    "id": "sjg3caHwU_DI"
   }
  },
  {
   "cell_type": "code",
   "source": "from object_extraction import *",
   "metadata": {
    "id": "6VOSW2cZaTsl",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:19:59.780085Z",
     "iopub.execute_input": "2024-09-23T12:19:59.780525Z",
     "iopub.status.idle": "2024-09-23T12:19:59.787275Z",
     "shell.execute_reply.started": "2024-09-23T12:19:59.780489Z",
     "shell.execute_reply": "2024-09-23T12:19:59.785956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Laden wir ein Bild!",
   "metadata": {
    "id": "BurvOeaVQi53"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "def show_image(im):\n",
    "    imshow(im)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks([]); ax.set_yticks([]);\n",
    "    return ax\n",
    "\n",
    "def choose_an_image():\n",
    "    \"\"\"\n",
    "    Wähle eine Datei aus <pfad_zu_daten> und stelle es dar\n",
    "    \"\"\"\n",
    "    Bilddatei_Liste = pd.Series(pfad_zu_daten.iterdir())\n",
    "    fn = Bilddatei_Liste.sample(1).values[0]\n",
    "    im = load_file(fn)\n",
    "    return im\n",
    "\n",
    "#im = choose_an_image()\n",
    "im = load_file('Daten/fork-big_04.jpg')\n",
    "show_image(im)"
   ],
   "metadata": {
    "id": "714f7266-4983-41c2-a473-a444419bf607",
    "outputId": "a2bee030-c7c5-49d1-a050-6353fba81b8e",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:20:02.678540Z",
     "iopub.execute_input": "2024-09-23T12:20:02.678958Z",
     "iopub.status.idle": "2024-09-23T12:20:04.713980Z",
     "shell.execute_reply.started": "2024-09-23T12:20:02.678928Z",
     "shell.execute_reply": "2024-09-23T12:20:04.712596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Adaption der Parameter\nWir haben Zugriff auf die Bilddaten, nun möchten wir die Parameterwerte auswählen, welche die Objekte gut vom Hintergrund isolieren. Die Funktion `process_file` erledigt das.\n\nDas Vorgehen dabei ist Folgendes:\n1. Lade das Bild und reduziere die Auflösung: Parameter **`pr`** enthält ein Tupel mit der Anzahl Pixelzeilen und der Anzahl Pixelspalten. Dies dient hauptsächlich der Beschleunigung der weiteren Verarbeitung.\n2. Schneide jeweils an den Rändern einen Prozentsatz der Zeilen bzw. Spalten ab: Der Prozentsatz der Zeilen ist durch **`fr`**, jener der Spalten durch **`fc`** gegeben.\n3. Es wird ein Schwellwert auf den value-Wert (in der hsv-Farbdarstellung) angewendet, um den dunklen (`sign`=+1) oder hellen (`sign`=-1) Hintergrund zu erkennen. Dies ergibt eine Maske (binärer Array), welcher Vordergrundpixel identifiziert.\n4. Es werden kleine Artefakte auf der Maske durch Erosion und Dilatation entfernt. Die Parameter `es` und `ds` geben die Grössen der Erosions- und Dilatationsmasken an.\n5. Die Objekte werden ausgeschnitten, d.h. separate Objekte werden identifiziert, und um jedes Objekt wird eine enge rechteckige *Bounding Box* gesetzt.\n6. Sollte der Ausschnitt weniger als **`mpx`** Pixel enthalten, wird er verworfen. Dies ist nötig, weil manchmal Reflexionen o.ä. zusätzliche kleine Ausschnitte erzeugen, welche aber nicht ein Objekt enthalten.\n7. Ein neues Bild wird abgespeichert, welches nur noch das (ausgeschnittene) Bildelement enthält.\n\n\nWenn dies gelingt, sind die Bilder in einer geeigneten Form für Deep Learning.\n\nIm Folgenden wird dieser Vorgang für ein (von Ihnen gewähltes) Bild durchgeführt. Passen Sie die Parameter so an, dass die Extraktion gut gelingt.  \nDie Parameter sollten Sie hier anpassen:",
   "metadata": {
    "id": "I7fPFODOa8vh"
   }
  },
  {
   "cell_type": "markdown",
   "source": "\n### Schritt 0: Laden des Bildes",
   "metadata": {
    "id": "EhxbY5fUfYjO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#im = choose_an_image()\n",
    "im = load_file('Daten/fork-small-01.jpg')\n",
    "show_image(im);"
   ],
   "metadata": {
    "id": "Wk64n5bafwTq",
    "outputId": "d5a3dc6a-f0ad-4e1a-a3f2-24eac0fdc4d3",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:21:09.341870Z",
     "iopub.execute_input": "2024-09-23T12:21:09.342297Z",
     "iopub.status.idle": "2024-09-23T12:21:11.426482Z",
     "shell.execute_reply.started": "2024-09-23T12:21:09.342264Z",
     "shell.execute_reply": "2024-09-23T12:21:11.425166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Das Bild hat aktuell die Auflösung",
   "metadata": {
    "id": "dhtA4iZFoi53"
   }
  },
  {
   "cell_type": "code",
   "source": "im.shape",
   "metadata": {
    "id": "vqRf2UhkokkI",
    "outputId": "0febd121-3201-40c1-da22-0836c2faf720",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:21:16.859278Z",
     "iopub.execute_input": "2024-09-23T12:21:16.859729Z",
     "iopub.status.idle": "2024-09-23T12:21:16.867775Z",
     "shell.execute_reply.started": "2024-09-23T12:21:16.859693Z",
     "shell.execute_reply": "2024-09-23T12:21:16.866291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Schritt 1: Auflösungsreduktion",
   "metadata": {
    "id": "5cqQIb4IewDY"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Die Bilder können zu hoch aufgelöst sein für unsere Anwendung, wodurch sich die Rechenzeit der folgenden Operationen vervielfacht. Die Vorverarbeitungsroutine `object_extraction.py` beginnt daher damit, mit der `--preprocessing_resolution` (oder `-pr`) das Bild zu verkleinern:",
   "metadata": {
    "id": "0ab41294-5fd3-41ef-8064-0f278e9310a2"
   }
  },
  {
   "cell_type": "code",
   "source": "im_resized = (255*resize(im,pr)).astype('uint8')\nshow_image(im_resized);",
   "metadata": {
    "id": "ae4c7c45-6911-4b6d-bbb5-214ad8ec9a34",
    "outputId": "fbf8c8fb-f768-450b-99f4-d150e9582871",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:50:52.311789Z",
     "iopub.execute_input": "2024-09-23T12:50:52.312254Z",
     "iopub.status.idle": "2024-09-23T12:50:54.257023Z",
     "shell.execute_reply.started": "2024-09-23T12:50:52.312218Z",
     "shell.execute_reply": "2024-09-23T12:50:54.255757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Die Auflösung sollte nun Ihren Wünschen entsprechen (`NrRows`, `NrCols`, Anzahl Farbkanäle):",
   "metadata": {
    "id": "4nQrnASmgU2O"
   }
  },
  {
   "cell_type": "code",
   "source": "im_resized.shape",
   "metadata": {
    "id": "zSjzORA4gUbu",
    "outputId": "50c03401-ec83-4795-cc6e-52324f2e4463",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:50:58.793255Z",
     "iopub.execute_input": "2024-09-23T12:50:58.793663Z",
     "iopub.status.idle": "2024-09-23T12:50:58.802426Z",
     "shell.execute_reply.started": "2024-09-23T12:50:58.793632Z",
     "shell.execute_reply": "2024-09-23T12:50:58.800920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Schritt 2: Ränder abschneiden\nAls nächstes müssen ev. die Ränder des Bildes überdeckt werden. Damit können Artefakte beseitigt werden, z.B. wenn der schwarze Hintergrund nicht bis an den Rand des Bildes reicht. `fraction_of_rows_to_remove` und `fraction_of_cols_to_remove` geben an, wieviel abgeschnitten wird. Aufgefüllt werden die Pixel mit dem Wert `value_to_fill=0` (in allen Farbkanälen).",
   "metadata": {
    "id": "a8JXy4r8gB2n"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#im_filled = fill_borders(im_resized,value_to_fill=0,fraction_of_rows_to_remove=0.1,fraction_of_cols_to_remove=0)\n",
    "im_filled = fill_borders_separate(im_resized, top_fraction=tf, bottom_fraction=bf, left_fraction=lf, right_fraction=rf)\n",
    "\n",
    "show_image(im_filled);"
   ],
   "metadata": {
    "id": "6e9ffdcd-7625-4924-a00a-2ee07e144477",
    "outputId": "4cce8a18-fb04-4155-b4d9-d2af303e3a9f",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:51:06.228934Z",
     "iopub.execute_input": "2024-09-23T12:51:06.229365Z",
     "iopub.status.idle": "2024-09-23T12:51:06.457192Z",
     "shell.execute_reply.started": "2024-09-23T12:51:06.229327Z",
     "shell.execute_reply": "2024-09-23T12:51:06.455931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "**Aufgabe 1:** Finden Sie für Ihre Bilder passende Werte für `fraction_of_rows_to_remove` und `fraction_of_cols_to_remove`.",
   "metadata": {
    "id": "5ea3c563-a6e9-48db-852c-4360be8ac22b"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Schritt 3: Hintergrundschwellwert bestimmen\nWählen Sie zunächst sign=+1 für Schwarzen Hintergrund oder sign=-1 für weissen Hintergrund.",
   "metadata": {
    "id": "7BdTHYftia7n"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Als nächstes soll ein Schwellwert im Farbraum das Objekt vom Hintergrund isolieren. Wir arbeiten im *hsv*-Raum: hue, saturation und value sind die drei Farbdimensionen, für welche jeweils ein Mindestwert (für sign=+1) bzw. Maximalwert (für sign=-1) für Vordergrundpixel festgelegt werden kann. Berechnet wird konkret: `mask = sign*im_hsv[:,:,2]>value_schwellwert*sign` (etc.).",
   "metadata": {
    "id": "fdb69399-823a-401f-b019-587badf73425"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mask = generate_mask_with_hsv_threshold(im_filled,hue_threshold=None,saturation_threshold=None, value_threshold=vth)\n",
    "\n",
    "plt.figure();show_image(mask);\n",
    "\n",
    "masked_image = create_masked_image(im_filled,mask)\n",
    "plt.figure();show_image(masked_image);"
   ],
   "metadata": {
    "id": "07cd9284-8866-4833-8a1b-157dbf83c3d9",
    "outputId": "cd12c153-80f7-4ea9-a779-20858db54b2a",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:53:43.802357Z",
     "iopub.execute_input": "2024-09-23T12:53:43.802815Z",
     "iopub.status.idle": "2024-09-23T12:53:44.149305Z",
     "shell.execute_reply.started": "2024-09-23T12:53:43.802774Z",
     "shell.execute_reply": "2024-09-23T12:53:44.147463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "**Aufgabe 2:** Finden Sie Werte für `hue_schwellwert`, `saturation_schwellwert` und `value_schwellwert` so, dass die Maske möglichst gut zum Objektumriss passt. Bei der Wahl der Schwellwerte muss man aufpassen, dass sie nicht nur auf diesem einen Bild passen, sondern auch auf allen anderen!",
   "metadata": {
    "id": "6a3b8278-fb20-4d95-8887-88129d10c60f"
   }
  },
  {
   "cell_type": "code",
   "source": "help(generate_mask_with_hsv_threshold)",
   "metadata": {
    "id": "X1ed8eXio5hx",
    "outputId": "82a9a12b-573a-46aa-9454-a4d72db92649",
    "execution": {
     "iopub.status.busy": "2024-09-23T11:57:16.138362Z",
     "iopub.execute_input": "2024-09-23T11:57:16.139706Z",
     "iopub.status.idle": "2024-09-23T11:57:16.151892Z",
     "shell.execute_reply.started": "2024-09-23T11:57:16.139650Z",
     "shell.execute_reply": "2024-09-23T11:57:16.149815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Schritt 4: Erosion und Dilatationsfilgergrössen bestimmen",
   "metadata": {
    "id": "vTM96wR8CMUq"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Wenn Hintergrundregionen übrigbleiben, dann ergibt dies zusätzliche Trainingsbilder, welche nicht einer Klasse zugeordnet sind- und es kostet auch viel Rechenzeit. Kleine, isolierte Maskenpixel möchten wir daher als nächstes durch Erosion entfernen.",
   "metadata": {
    "id": "c0b921fa-3b03-4faf-a7bd-38224fccd76a"
   }
  },
  {
   "cell_type": "markdown",
   "source": "**Aufgabe 3:** Finden Sie Werte für es und ds, welche möglichst keine vereinzelte Hintergrundpixel in der Maske übrig lassen:",
   "metadata": {
    "id": "dc5a204c-9f2e-43ad-9de0-4b40b22efe51"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if es > 0 and ds > 0:\n",
    "    morphed_mask = morphology_transform(mask,shape = square,erosion_size=es,dilation_size=ds)\n",
    "else:\n",
    "    morphed_mask = mask\n",
    "show_image(morphed_mask);"
   ],
   "metadata": {
    "id": "416727e4-d552-47a1-821e-cf5fffc02a30",
    "outputId": "7b9c58d0-ced2-44b1-ffac-277628d0e3d5",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:04:52.780596Z",
     "iopub.execute_input": "2024-09-23T13:04:52.781029Z",
     "iopub.status.idle": "2024-09-23T13:04:52.896537Z",
     "shell.execute_reply.started": "2024-09-23T13:04:52.780997Z",
     "shell.execute_reply": "2024-09-23T13:04:52.894893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Ev. haben Sie auch Glück, und Sie sehen oben nur eine einzige zusammenhängende gelbe Struktur? Dann können Sie die Werte so lassen, wie sie sind!",
   "metadata": {
    "id": "xP2wGbuZC0tn"
   }
  },
  {
   "cell_type": "markdown",
   "source": "`create_mask` ist nun einfach eine Routine, welche die obigen Schritte der Maskenbildung zusammenfasst. Sie sollte das gleiche Bild `morphed_mask` wie oben erstellen:",
   "metadata": {
    "id": "9d3ac5e4-ebd7-44f3-adb4-6d36d2a9f103"
   }
  },
  {
   "metadata": {
    "id": "20d7ef28-2d0b-46a2-b3e2-c43ce52a0800",
    "outputId": "919015ba-9553-415b-8962-f5c763451fe0",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:09:44.217796Z",
     "iopub.execute_input": "2024-09-23T13:09:44.218542Z",
     "iopub.status.idle": "2024-09-23T13:09:44.359366Z",
     "shell.execute_reply.started": "2024-09-23T13:09:44.218506Z",
     "shell.execute_reply": "2024-09-23T13:09:44.357484Z"
    },
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "morphed_mask,im_filled  = create_mask(im_resized,top_fraction=tf, bottom_fraction=bf, left_fraction=lf, right_fraction=rf,hue_threshold=None,saturation_threshold=None,value_threshold=vth,erosion_size=es,dilation_size=ds)\n",
    "show_image(morphed_mask);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Nun wird die Maske benutzt, um das Objekt (oder die Objekte) aus dem Bild auszuschneiden:",
   "metadata": {
    "id": "217de670-9cea-42cb-a88f-51d74a6b2120"
   }
  },
  {
   "cell_type": "code",
   "source": "masked_image = create_masked_image(im_filled,morphed_mask)\nshow_image(masked_image);\nmasked_image.shape",
   "metadata": {
    "id": "fa05afc1-1435-4f60-ae6f-5ead867e8cf2",
    "outputId": "f13adb0a-e4a0-4cd1-e7ef-dd9b0e44caa2",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:09:58.411074Z",
     "iopub.execute_input": "2024-09-23T13:09:58.411446Z",
     "iopub.status.idle": "2024-09-23T13:09:58.569480Z",
     "shell.execute_reply.started": "2024-09-23T13:09:58.411419Z",
     "shell.execute_reply": "2024-09-23T13:09:58.567986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Hier sollte ein Bild zu sehen sein, welches einen komplett schwarzen Hintergrund hat, und nur die relevanten Objekte zeigt. Als nächstes hätten wir gerne von jedem Objekt ein separates Bild, so dass wir darauf unseren Bildklassifikator trainieren können.",
   "metadata": {
    "id": "0RooNBffDLqU"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Schritt 5: Objekte ausschneiden\nWir haben den Hintergrund eliminiert. Damit ist es nun leichter, die Objekte voneinander zu trennen. Eine Funktion von [scikit-image](https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.label) tut dies:",
   "metadata": {
    "id": "kf5B_pYw_zzx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from skimage.measure import label\n",
    "label_img = label(morphed_mask)\n",
    "show_image(label_img)\n",
    "plt.colorbar();"
   ],
   "metadata": {
    "id": "1993d5f7-b549-418e-98ef-f4f6e1401a89",
    "outputId": "53424d58-df57-4152-c125-0607e322bc6a",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:10:17.402596Z",
     "iopub.execute_input": "2024-09-23T13:10:17.403003Z",
     "iopub.status.idle": "2024-09-23T13:10:17.619763Z",
     "shell.execute_reply.started": "2024-09-23T13:10:17.402973Z",
     "shell.execute_reply": "2024-09-23T13:10:17.618549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Falls das obige Bild wie eine Maske aussieht: Vermutlich liegt nur ein Bild vor- deren Pixel wird dann mit dem Wert \"1\" aufgefüllt. Wäre ein zweites Objekt vorhanden, würde dieses mit dem Wert \"2\" aufgefüllt und wäre in einer leicht anderen Farbe sichtbar. Aus diesem gelabelten Bild werden nun Teilbilder extrahiert, welche jeweils nur ein Objekt enthalten:",
   "metadata": {
    "id": "Um8l3kxJ-eXv"
   }
  },
  {
   "cell_type": "code",
   "source": "label_img.shape,masked_image.shape",
   "metadata": {
    "id": "eVNmP2w6Dv7R",
    "outputId": "fe9d8b8e-f4e0-4ab6-d30a-841f73ed5f90",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:10:46.140019Z",
     "iopub.execute_input": "2024-09-23T13:10:46.140407Z",
     "iopub.status.idle": "2024-09-23T13:10:46.148986Z",
     "shell.execute_reply.started": "2024-09-23T13:10:46.140377Z",
     "shell.execute_reply": "2024-09-23T13:10:46.147454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "regionlist,regions = extract_regions(label_img,masked_image,fraction_of_rows_to_remove=tf+bf)\n",
    "len(regionlist)"
   ],
   "metadata": {
    "id": "v_Pq1n5a9cKL",
    "outputId": "537929b1-2a00-4483-c202-2e106fa97324",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:10:50.596187Z",
     "iopub.execute_input": "2024-09-23T13:10:50.596560Z",
     "iopub.status.idle": "2024-09-23T13:10:50.608138Z",
     "shell.execute_reply.started": "2024-09-23T13:10:50.596533Z",
     "shell.execute_reply": "2024-09-23T13:10:50.607009Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Alle obigen Schritte sind in der Funktion image_preprocessing zusammengefasst:",
   "metadata": {
    "id": "p6ieGKnyAKrO"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "code",
   "source": [
    "regionlist,regions,mask,masked_image = image_preprocessing(im_resized,top_fraction=tf,bottom_fraction=bf,left_fraction=lf,right_fraction=rf,value_threshold=vth,erosion_size=es,dilation_size=ds)\n",
    "print(f\"Anzahl gefundene Bereiche: {len(regionlist)}\")"
   ],
   "metadata": {
    "id": "5757e34f-2c4e-4ff0-88cf-912d8d291216",
    "outputId": "d9bdc899-216b-4972-a032-bb5307f25825",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:11:06.722586Z",
     "iopub.execute_input": "2024-09-23T13:11:06.723020Z",
     "iopub.status.idle": "2024-09-23T13:11:09.786889Z",
     "shell.execute_reply.started": "2024-09-23T13:11:06.722987Z",
     "shell.execute_reply": "2024-09-23T13:11:09.784965Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "label_img.shape,masked_image.shape,len(regions)",
   "metadata": {
    "id": "kpOIJ46JD-aM",
    "outputId": "669ad360-ac15-4ca9-eeff-89b6da72d092",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:11:18.735737Z",
     "iopub.execute_input": "2024-09-23T13:11:18.736229Z",
     "iopub.status.idle": "2024-09-23T13:11:18.745132Z",
     "shell.execute_reply.started": "2024-09-23T13:11:18.736195Z",
     "shell.execute_reply": "2024-09-23T13:11:18.743908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "show_image(masked_image)",
   "metadata": {
    "id": "I4dvh4iqED92",
    "outputId": "387fcedb-57cd-4ebb-c07c-5e4ef5c6e5b9",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:11:22.242217Z",
     "iopub.execute_input": "2024-09-23T13:11:22.242671Z",
     "iopub.status.idle": "2024-09-23T13:11:24.472067Z",
     "shell.execute_reply.started": "2024-09-23T13:11:22.242607Z",
     "shell.execute_reply": "2024-09-23T13:11:24.470799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Schritt 6: Kleine Objekte (Artefakte) ignorieren\nManchmal sind einige der gefundenen Regionen viel zu klein, um echte Objekte zu sein. Es gibt eine Option `--minimum-number-of-pixels` bzw. `-mpx`, welche Regionen unterdrückt, welche zu klein sind. Die Grösse der Regionen wird hier ausgegeben, um diesen Parameter gut einstellen zu können.",
   "metadata": {
    "id": "YsKyqQ7J__Zc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if len(regionlist)<20:\n",
    "    for ireg,reg in enumerate(regions):\n",
    "        print(f\"Region {ireg}: {int(reg.area):>6}\")\n",
    "else:\n",
    "    #for ireg,reg in enumerate(regions):\n",
    "    #    print(f\"{int(reg.area):<3} \",end='')\n",
    "\n",
    "    plt.hist([reg.area for reg in regions],bins=np.logspace(1,6,100))\n",
    "    plt.gca().set_xscale('log') #ev. sieht man damit etwas mehr\n",
    "    plt.gca().set_yscale('log')"
   ],
   "metadata": {
    "id": "c1d20a49-38b7-42da-ac50-41eca0f238e5",
    "outputId": "940176ef-c782-47a8-e33d-fd4d25ea5dba",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:11:44.213299Z",
     "iopub.execute_input": "2024-09-23T13:11:44.214222Z",
     "iopub.status.idle": "2024-09-23T13:11:44.222415Z",
     "shell.execute_reply.started": "2024-09-23T13:11:44.214183Z",
     "shell.execute_reply": "2024-09-23T13:11:44.221126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Schauen wir uns die extrahierten Regionen an - es sollten nicht zu viele sein.",
   "metadata": {
    "id": "THqMe9_s4VGH"
   }
  },
  {
   "cell_type": "markdown",
   "source": "**Aufgabe 4:** Bestimmen Sie einen geeigneten Wert von `mpx`, so dass nur relevante Regionen übrig bleiben. Tragen Sie den Wert in die Parameterliste ein.\n\nDer `mpx`-Wert wird in der nächsten Zelle verwendet:",
   "metadata": {
    "id": "7f4c17f8-1b92-449c-aed4-f456f2e095f7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "relevante_regionen =  [reg for reg in regions if reg.area >= 200]\n",
    "if len(relevante_regionen)<20:\n",
    "  for reg in relevante_regionen:\n",
    "    plt.figure();\n",
    "    plt.imshow(reg.image_intensity);\n",
    "    plt.xticks([]);plt.yticks([]) # Wir brauchen keine x- und y-Achse\n",
    "else:\n",
    "  print(f\"Das würde {len(relevante_regionen)} Graphiken erzeugen! Ich mache lieber nichts...\")"
   ],
   "metadata": {
    "id": "bddc415b-0a75-428e-b9f6-42fe6928bbfd",
    "outputId": "ed69f2d3-5c77-46ea-bcc8-86bea0d89198",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:11:57.688093Z",
     "iopub.execute_input": "2024-09-23T13:11:57.688508Z",
     "iopub.status.idle": "2024-09-23T13:11:58.089287Z",
     "shell.execute_reply.started": "2024-09-23T13:11:57.688477Z",
     "shell.execute_reply": "2024-09-23T13:11:58.088013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Sehen Sie hier Ihre extrahierten Objekte, und keine (oder nur wenige) Artefakte?  \nJa?  \nWirklich?  \n**Cool!**  \nDann können wir nun versuchen, alle weiteren Daten zu verarbeiten. Das kann  in der Kommandozeile wie folgt erreicht werden:",
   "metadata": {
    "id": "98cb87c1-f854-4eb6-b304-5b79f759cd5d"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Ausgabepfad = Path('1_object_extraction_output')\n",
    "Ausgabepfad.mkdir(mode=644,exist_ok=True)\n",
    "Ausgabepfad"
   ],
   "metadata": {
    "id": "0nW1bdCVR4UQ",
    "outputId": "69e91826-6806-43b2-c32b-9db9b16d1aa4",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:13:21.837917Z",
     "iopub.execute_input": "2024-09-23T13:13:21.838876Z",
     "iopub.status.idle": "2024-09-23T13:13:21.847740Z",
     "shell.execute_reply.started": "2024-09-23T13:13:21.838827Z",
     "shell.execute_reply": "2024-09-23T13:13:21.846441Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "imgfns = list(Path('Daten').glob('*.'+Bilddateiendung))\n",
    "imgfns[:5]"
   ],
   "metadata": {
    "id": "RZA4bC_HTEjL",
    "outputId": "40b5817c-bcb2-4194-f7d8-6ff1b2cf401b",
    "execution": {
     "iopub.status.busy": "2024-09-23T13:13:28.972060Z",
     "iopub.execute_input": "2024-09-23T13:13:28.972460Z",
     "iopub.status.idle": "2024-09-23T13:13:29.002712Z",
     "shell.execute_reply.started": "2024-09-23T13:13:28.972430Z",
     "shell.execute_reply": "2024-09-23T13:13:29.001280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "yta = True #args.yes_to_all\n",
    "outputpath = Ausgabepfad\n",
    "outputpath_Ausschnitte = os.path.join(outputpath,'Ausschnitte')\n",
    "ask_path_creation(outputpath_Ausschnitte,yes_to_all=yta)\n",
    "\n",
    "top_fraction = float(tf)\n",
    "bottom_fraction = float(bf)\n",
    "left_fraction = float(lf)\n",
    "right_fraction = float(rf)\n",
    "\n",
    "preprocessing_resolution = [int(f) for f in pr]\n",
    "print('preprocessing_resolution ',preprocessing_resolution )\n",
    "erosion_size= intOrNone(1)\n",
    "dilation_size= intOrNone(3)\n",
    "hue_threshold = None#intOrNone(hth)\n",
    "value_threshold = 150#None#intOrNone(vth)\n",
    "saturation_threshold = None #intOrNone(sth)\n",
    "write_summary_file = False\n",
    "num_cores = 8 #int(args.num_cores)\n",
    "minimum_number_of_pixels = 400\n",
    "\n",
    "kwargs = {'top_fraction':tf,'bottom_fraction':bf,'left_fraction':lf,'right_fraction':rf,'hue_threshold':hue_threshold,'saturation_threshold':saturation_threshold,'value_threshold':vth,\n",
    "        'erosion_size':erosion_size,'dilation_size':dilation_size,'min_num_pixels':minimum_number_of_pixels,'outputpath':outputpath_Ausschnitte,'preprocessing_resolution':preprocessing_resolution}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-23T13:13:34.404212Z",
     "iopub.execute_input": "2024-09-23T13:13:34.404597Z",
     "iopub.status.idle": "2024-09-23T13:13:34.415193Z",
     "shell.execute_reply.started": "2024-09-23T13:13:34.404569Z",
     "shell.execute_reply": "2024-09-23T13:13:34.413826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "NrFilesToProcess = None # None eingeben für alle\n",
    "kwargs['num_cores']=8\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "main(imgfns[:NrFilesToProcess],kwargs)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-23T13:13:38.698572Z",
     "iopub.execute_input": "2024-09-23T13:13:38.699404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Alternativ kann die Ausgabe der folgenden Zelle genutzt werden, um in der Kommandozeile das Skript [object_extraction.py](https://gitlab.ost.ch/beat.toedtli/learning-city-lab/-/blob/main/1_object_extraction/object_extraction.py?ref_type=heads)[im Verzeichnis [1_object_extraction](https://gitlab.ost.ch/beat.toedtli/learning-city-lab/-/tree/main/1_object_extraction?ref_type=heads) auszuführen.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "cmd = f\"python3 '{pfad_zu_object_extraction}/object_extraction.py' \\\n",
    "-y -o '{Ausgabepfad}' -pr {pr[0]},{pr[1]} -tf {tf} -bf {bf} -lf {lf} -rf {rf} -es {es} -ds {ds} \\\n",
    "-vth {vth} -mpx {mpx} '{pfad_zu_daten_string}/*.jpg'\"\n",
    "print(\"Der Kommandozeilenbefehl lautet:\\n\",cmd)\n"
   ],
   "metadata": {
    "id": "305b016e-1324-4a0c-a815-b5a0f30af040",
    "outputId": "14947dd1-3153-49e4-9c81-bc0634d3a173",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.107782Z",
     "iopub.status.idle": "2024-09-23T12:05:28.108266Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.108057Z",
     "shell.execute_reply": "2024-09-23T12:05:28.108075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "#Die Ausschnitte sind nun hier:\nprint(Ausgabepfad/'Ausschnitte')\n# hier einige Beispiele:\n!ls {'\"'+str(Ausgabepfad/'Ausschnitte')+'\"'}|head -n 5",
   "metadata": {
    "id": "sv9BaqtCmAiv",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.109908Z",
     "iopub.status.idle": "2024-09-23T12:05:28.110327Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.110138Z",
     "shell.execute_reply": "2024-09-23T12:05:28.110153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Wir können uns die Ausschnitte anschauen:",
   "metadata": {
    "id": "89oNZWS0mL4Z"
   }
  },
  {
   "cell_type": "code",
   "source": "fn = Ausgabepfad/'Ausschnitte'/'rot-17_0_14.jpg'\nif fn.exists():\n    im = plt.imread(fn)\n    show_image(im);",
   "metadata": {
    "id": "zwGvJPIbmCHb",
    "outputId": "074f1773-e380-432e-d697-2f1c304c35b5",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.111999Z",
     "iopub.status.idle": "2024-09-23T12:05:28.112434Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.112246Z",
     "shell.execute_reply": "2024-09-23T12:05:28.112262Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Bevor wir die Bilder herunterladen, wollen wir sie in Unterordner pro Klasse anordnen. ",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Bilden von Unterordner pro Klasse\nKeras, unsere Deep Learning Bibliothek, hat eine einfache Routine, um Kategorisierte Bilder zu laden: Dazu müssen alle Bilder einer Klasse in einem Unterordner liegen, welcher als Namen die Klassenbezeichnung trägt. Diese Zuordnung kann natürlich von Hand vorgenommen werden. Im Fall des Giraffendatensatzes ist das Klassenlabel aber bereits im Dateinamen der Bilder codiert.\n\nUm den Klassennamen 'rot' aus dem Dateinamen 'rot-17_0_10.jpg' zu extrahieren, sind reguläre Ausdrücke sehr nützlich. Reguläre Ausdrücke sind ziemlich kryptisch, aber mächtig und (nach etwas Übung) durchaus handlich.  \nWir importieren zunächst die Standard-[Python-Bibliothek](https://docs.python.org/3/library/re.html), welche reguläre Ausdrücke implementiert:",
   "metadata": {
    "id": "Ag2iY2BHtL7A"
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### Reguläre Ausdrücke",
   "metadata": {
    "id": "-CH3GTZNAchY"
   }
  },
  {
   "cell_type": "code",
   "source": "import re\nhelp(re.sub) #oder re.sub?",
   "metadata": {
    "id": "dh92H89guxU6",
    "outputId": "39e1eb34-17f1-45c7-d2d5-396c243023f6",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.114407Z",
     "iopub.status.idle": "2024-09-23T12:05:28.114986Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.114702Z",
     "shell.execute_reply": "2024-09-23T12:05:28.114725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "re.sub('^([^-]*)-.*$','\\\\1','rot-17_0_10.jpg')",
   "metadata": {
    "id": "qbVNRGr6u2pm",
    "outputId": "68bd827d-bcee-4d47-e9e9-027ad3cdaad8",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.116206Z",
     "iopub.status.idle": "2024-09-23T12:05:28.116577Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.116400Z",
     "shell.execute_reply": "2024-09-23T12:05:28.116414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Der reguläre Ausdruck `^([^-]*)-.*$` hat's durchaus in sich, ist aber verständlicher, wenn man folgendes weiss:  \n- `^` bezeichnet den Beginn einer Zeichenkette\n- `$` bezeichnet das Ende einer Zeichenkette\n- `.` bezeichnet ein beliebiges Zeichen\n- `*` meint \"Null-mal, einmal oder beliebig oft\". Gemeint ist hier das Zeichen davor (\".\"), als \"kein oder beliebig viele beliebige Zeichen\".\n- `( )` Die Klammern gehören zusammen und bilden eine Gruppe: alle Zeichen dazwischen werden in einer Variablen abgespeichert, welche \"\\1\" heisst. Dies sind die einzigen Zeichen, welche nach der Substitution die verbleibende Zeichenkette ausmachen: Im zweiten Argument von `re.sub` steht, womit ein \"gematchtes Muster\" (engl. matched pattern) im String ersetzt wird.\n- In eckigen Klammern, `[]`, können Zeichen aufgezählt werden, die auftauchen dürfen. Innerhalb von eckigen Klammern bedeutet `^` *nicht* den Beginn des Strings, sondern eine Negation. Der Ausdruck `[^-]` bezeichnet daher ein beliebiges Zeichen, welches aber nicht das Minuszeichen sein darf.\n\nInsgesamt sagt der Ausdruck `'^([^-]*)-.*$'` also so etwas wie:  \n*Eine Zeichenkette matcht, wenn sie mit einer beliebigen Folge von Zeichen beginnt, welche nicht das Zeichen \"-\" ist, gefolgt von einem Minuszeichen. Diese Zeichen vor dem Minus bilden die Gruppe 1. Nach dieser Gruppe muss also ein \"-\" folgen, und danach dürfen noch beliebig viele beliebige Zeichen folgen bis zum Ende der Zeichenkette. Ersetze diese ganze Zeichenkette (von Anfang bis Ende) mit der Gruppe.*\n\nIn einfacherer Sprache ausgedrückt wird die Zeichenkette vor dem Minuszeichen extrahiert- sie enthält ja den Klassennamen.",
   "metadata": {
    "id": "84EVnLHfvG41"
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### Pandas DataFrames\nPandas DataFrames sind sehr nützliche tabellenartige Strukturen. Sie eignen sich v.a. für die Datenanalyse und Visualisierung von strukturierten Daten. Im Folgenden werden diese genutzt, um das Klassenlabel zu bestimmen, welches für die Erstellung der Baumstruktur nützlich ist.",
   "metadata": {
    "id": "u6zYdPA3AgwM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "volle_Dateinamen = [full_file_name for full_file_name in (Ausgabepfad/'Ausschnitte').glob('*.jpg')]\n",
    "Basisnamen =  [full_file_name for full_file_name in (Ausgabepfad/'Ausschnitte').glob('*.jpg')]\n",
    "\n",
    "#Basisnamen = [re.sub(r'^([^-]*-\\d+).*$','\\\\1',bn.name) for bn in volle_Dateinamen] #Wende den regulären Ausdruck an\n",
    "Klassenlabel = [re.sub(r'^([^-]*)-.*$','\\\\1',bn.name) for bn in Basisnamen] #Wende den regulären Ausdruck an\n",
    "#Einfach nur, weil's cool ist: Pandas DataFrames! Hier eröffnet sich eine ganze Welt von Möglichkeiten\n",
    "df = pd.DataFrame({'Dateiname':volle_Dateinamen,'Basisname':Basisnamen,'Klassenlabel':Klassenlabel})\n",
    "df"
   ],
   "metadata": {
    "id": "lcrqzup9tKje",
    "outputId": "a215e716-c8cf-47ae-e8ba-663d68a49f81",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.118085Z",
     "iopub.status.idle": "2024-09-23T12:05:28.118493Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.118297Z",
     "shell.execute_reply": "2024-09-23T12:05:28.118314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "#### Train-Test-Split\nAn dieser Stelle lohnt es sich, kurz innezuhalten: Unsere grandiose Strategie ist es, aus Bildern Objekte zu extrahieren und auf diesen dann ein Modell zu trainieren. Aber wir können nicht alle Daten als Trainingsdaten verwenden, sonst haben wir nichts mehr, um die *Generalisierungsfähigkeit* unseres Modells zu messen!  \nDie Realität ist, dass wir nur ungern später nochmals neue Daten aufnehmen wollen. Die Liste in `df` oben ist alles, was uns zur Verfügung steht. Es macht daher Sinn, bereits jetzt einen Teil dieser Daten zurückzulegen und zu *schwören* diese Daten nicht für das Training zu benutzen. Wir brauchen ca. 20% *frische* Daten, an denen wir die Verallgemeinerungsfähigkeit unseres Modells überprüfen können.  \n[Scikit-Learn](https://scikit-learn.org) bietet uns [hier](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py) verschiedene Strategien an, wie wir aus unseren Trainingsdaten einen Testdatensatz absondern können. Wir könnten einfach [zufällig splitten](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit). Das ist naiv. Lieber eine [k-fache Kreuzvalidierung](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold). Aber was, wenn zufälligerweise eine Klasse nur im Testdatensatz auftaucht, und gar nicht im Trainingsdatensatz?! Also [stratifizieren](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) wir. Ok- und was ist, wenn wir überprüfen wollen, dass wir in Bezug auf eine bestimmte Untergruppierung (z.B. nach Geschlecht, Ethnie,...) gut von einer Gruppe auf eine andere verallgemeinern können müssen? Dann darf eine [Gruppe nur in einem Fold vorkommen](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedGroupKFold.html#sklearn.model_selection.StratifiedGroupKFold). Sie sehen- richtig zu splitten kann herausfordernd sein!  \nHier jedenfalls möchten wir zumindest stratifizieren. Wir nehmen mal [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold), um unsere Daten zu splitten.",
   "metadata": {
    "id": "NVdpxz9ZI7Zn"
   }
  },
  {
   "cell_type": "code",
   "source": "from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nXtrain,Xtest,ytrain,ytest = train_test_split(df[['Dateiname','Basisname']],df.Klassenlabel,test_size=0.2,train_size=0.8,stratify =df.Klassenlabel,random_state=42)\n# Das Fixieren des random_state bedeutet, dass immer der gleiche Split gemacht wird. Dadurch wird verhindert, dass durch mehrfaches durchlaufen immer mal wieder andere Daten für das Training\n# benutzt werden. Denn dadurch würde man sich letztlich beim Training alle Daten anschauen, auch die Testdaten. Subtiler Punkt- aber m.E. good practice!\n#Die Grössen der Arrays:\nprint(Xtrain.shape,Xtest.shape,ytrain.shape,ytest.shape)\nprint(\"Trainingsdaten\")\ndisplay(ytrain.value_counts())\nprint(\"\\nTestdaten\")\ndisplay(ytest.value_counts())\nprint('\\nKlassenverhältnis:')\n#Von den Trainingsdaten gibt es in jeder Klasse etwa gleichviel mehr als in den Testdaten:\nytest.value_counts()/ytrain.value_counts()",
   "metadata": {
    "id": "iLz-EwHsNFkR",
    "outputId": "78411f83-4459-454d-e049-9ebd5c249c31",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.120251Z",
     "iopub.status.idle": "2024-09-23T12:05:28.120677Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.120461Z",
     "shell.execute_reply": "2024-09-23T12:05:28.120477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Die Ausgaben oben zeigen die Anzahl Beispiele pro Klasse in den Training- und Testdaten sowie das Verhältnis pro Klasse. Das Verhältnis sollte für alle Klasse etwa gleich gross sein- dies nennt sich *stratifiziertes Training-Test-Splitten*.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "display(Xtrain.head())\nytrain",
   "metadata": {
    "id": "jQjOTVmKQ_vk",
    "outputId": "37f26a89-f374-4eb6-b631-f6fca0e7560f",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.122206Z",
     "iopub.status.idle": "2024-09-23T12:05:28.122590Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.122406Z",
     "shell.execute_reply": "2024-09-23T12:05:28.122421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "#### Shutil - High-level File Operations\nWir kopieren nun die Daten in Unterordner von `pfad_zu_lcl_colab/2_Baumstruktur/`. Die Unterordner sollen die Klassennamen (Farben) sein.",
   "metadata": {
    "id": "xiIBte_KAm6Z"
   }
  },
  {
   "cell_type": "code",
   "source": "import shutil\n#Kopiere die Trainigsdaten\nfor Basisname,voller_Dateiname, label in zip(Xtrain.Basisname,Xtrain.Dateiname, ytrain):\n    src = voller_Dateiname\n    #dst = Path('/tmp','2_Baumstruktur',label)\n    dst_train = Ausgabepfad/'2_Baumstruktur_train'/label\n\n    dst_train.mkdir(exist_ok=True,parents=True)\n    shutil.copy(src,dst_train/Basisname.name)\nprint(f\"Trainingsdateien wurden nach {str(dst_train.parent)} kopiert.\")\n#Kopiere die Testdaten\nfor Basisname,voller_Dateiname, label in zip(Xtest.Basisname,Xtest.Dateiname, ytest):\n    src = voller_Dateiname\n    #dst = Path('/tmp','2_Baumstruktur',label)\n    dst_test = Ausgabepfad/'2_Baumstruktur_test'/label\n\n    dst_test.mkdir(exist_ok=True,parents=True)\n    shutil.copy(src,dst_test/Basisname.name)\nprint(f\"Testdateien wurden nach {str(dst_test.parent)} kopiert.\")",
   "metadata": {
    "id": "szzCAw_V7Yh0",
    "outputId": "2780b886-baf5-46a2-a3ee-ce7068a10798",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.124847Z",
     "iopub.status.idle": "2024-09-23T12:05:28.125238Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.125051Z",
     "shell.execute_reply": "2024-09-23T12:05:28.125066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Überprüfen wir die Struktur! Die Klassenverzeichnisse sind hier:",
   "metadata": {
    "id": "DN_oieygCBq6"
   }
  },
  {
   "cell_type": "code",
   "source": "!echo \"Training-Baumstruktur:\"\n!ls \"{dst_train.parent}\"\n!echo \"Test-Baumstruktur:\"\n!ls \"{dst_test.parent}\"",
   "metadata": {
    "id": "IN2Y7LblCJeQ",
    "outputId": "47662c32-96b6-4ef9-8f8d-20f7aed04411",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.127234Z",
     "iopub.status.idle": "2024-09-23T12:05:28.127656Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.127448Z",
     "shell.execute_reply": "2024-09-23T12:05:28.127465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Und darunter befinden sich die zur Klasse zugehörigen Bilder:",
   "metadata": {
    "id": "wotx8Zj3CLeG"
   }
  },
  {
   "cell_type": "code",
   "source": "!ls \"{dst_test.parent}\"/*",
   "metadata": {
    "id": "uLPssRPwBoD2",
    "outputId": "491944ed-6d7c-41cc-b7f4-b08dfd6f17f5",
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.129561Z",
     "iopub.status.idle": "2024-09-23T12:05:28.130122Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.129849Z",
     "shell.execute_reply": "2024-09-23T12:05:28.129871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Nun wollen wir diese zwei Baumstrukturen herunterladen:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from IPython.display import FileLink\n! echo \"-Trainingdaten-\"\n! zip -r training_Baumstruktur.zip {dst_train.parent}/*|tail -n5\n! echo \"-Testdaten-\"\n! zip -r testing_Baumstruktur.zip {dst_test.parent}/*|tail -n5\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.132418Z",
     "iopub.status.idle": "2024-09-23T12:05:28.132853Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.132653Z",
     "shell.execute_reply": "2024-09-23T12:05:28.132674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Die folgenden Ausgaben geben einen Link an. Bitte klicken Sie ihn an und speichern Sie die .zip-Datei lokal ab. Sie sollten sie anschliessend extrahieren und überprüfen, ob die Baumstruktur stimmt.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "FileLink(r'training_Baumstruktur.zip')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.134522Z",
     "iopub.status.idle": "2024-09-23T12:05:28.135061Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.134746Z",
     "shell.execute_reply": "2024-09-23T12:05:28.134762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "FileLink(r'testing_Baumstruktur.zip')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-23T12:05:28.136594Z",
     "iopub.status.idle": "2024-09-23T12:05:28.137064Z",
     "shell.execute_reply.started": "2024-09-23T12:05:28.136864Z",
     "shell.execute_reply": "2024-09-23T12:05:28.136881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "**Gratulation!!!** Damit sind wir bereit für das Training eines neuronalen Netzes. Weiter geht's im Notebook `2_training/Training.ipynb.",
   "metadata": {
    "id": "veEzaquiCScN"
   }
  }
 ]
}
